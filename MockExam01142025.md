# Mock Exam Questions for Generative AI Engineers

## Section 1: Design Applications – 14%

**  1. A Generative AI Engineer is tasked with designing a system to classify customer feedback into specific categories.
What is the first step to ensure the output format aligns with the business requirements?

A. Test multiple models with default settings\
B. Design a prompt that specifies the exact format for the response\
C. Fine-tune the model with additional labeled data\
D. Use a pre-trained classification model directly

A business requirement involves summarizing legal documents for non-technical users. Which component should the engineer prioritize in the AI pipeline?
A. Data chunking module
B. Sentiment analysis model
C. Text summarization model
D. Translation model

To ensure the AI pipeline’s multi-stage reasoning is effective, what is a critical step?
A. Optimize the final output’s token count
B. Order tools logically to gather and process information
C. Minimize the use of external APIs
D. Avoid any user feedback loops

A Generative AI Engineer must design a prompt to elicit responses formatted as JSON. Which technique will ensure the prompt works correctly?
A. Fine-tune the model on a dataset containing only JSON data
B. Use a prompt with explicit examples of JSON-formatted responses
C. Limit the length of the prompt to improve clarity
D. Implement a token-level optimization strategy

How can a Generative AI Engineer translate a use case requiring a step-by-step guide into a successful model design?
A. Choose a task-agnostic model to handle the input
B. Write a description focusing on input, processing steps, and desired output
C. Avoid providing the model with specific task details
D. Use a multilingual dataset to train the model

Section 2: Data Preparation – 14%

A document containing both structured and unstructured data is fed into a retrieval-augmented generation (RAG) pipeline. What is the best chunking strategy?
A. Fixed number of sentences per chunk
B. Adaptive chunking based on document structure
C. Randomly splitting the document
D. Using entire paragraphs as chunks

How should an engineer address noisy or irrelevant content in source documents for a RAG application?
A. Perform data deduplication only
B. Filter extraneous content that negatively affects quality
C. Include the noisy content to maintain context
D. Use all available data without filtering

Which Python package is most appropriate for extracting text from PDFs in a RAG pipeline?
A. NLTK
B. PyPDF2
C. Pandas
D. Matplotlib

To write chunked text into Delta Lake tables for use in Unity Catalog, what sequence should the engineer follow?
A. Chunk, label, and load data in one step
B. Define chunk structure, apply transformations, and write to Delta Lake
C. Process all text without chunking and directly write to Delta Lake
D. Use raw text as-is without any formatting

Which approach best ensures the quality of source documents in a RAG application?
A. Randomly sample documents without manual review
B. Identify and select documents that provide necessary and high-quality knowledge
C. Use documents regardless of their format or quality
D. Automatically accept all uploaded documents

Section 3: Application Development – 30%

What is the primary benefit of selecting LangChain for a generative AI application?
A. It ensures the application will not hallucinate
B. Provides modular tools for chaining prompts and responses
C. Reduces the need for data preprocessing
D. Increases the model’s response latency

A user complains about an LLM’s irrelevant responses. What action should the engineer take?
A. Re-train the LLM on user-provided feedback
B. Modify the prompt to clarify intent
C. Increase the model’s token limit
D. Use a smaller model for faster results

To implement guardrails in an LLM application, which approach is most effective?
A. Limit the input token count
B. Apply filters and validation layers to outputs
C. Use only pre-trained models
D. Avoid user inputs entirely

An LLM consistently generates offensive outputs in certain contexts. Which solution should NOT be considered?
A. Fine-tune the model to improve behavior
B. Add a post-processing filter for generated text
C. Ignore the behavior as user misuse
D. Implement stricter prompt guidelines

To create a prompt template for exposing available functions, what should the engineer include?
A. Generic instructions without examples
B. Clear descriptions of each function’s purpose and usage
C. Random examples unrelated to the task
D. Only one function example

Section 4: Assembling and Deploying Applications – 22%

Which step is critical when coding a chain using LangChain?
A. Implement recursive prompts
B. Specify input-output schemas for each step
C. Use only one model in the chain
D. Avoid using any external dependencies

A Generative AI Engineer is deploying an endpoint for a RAG application. What is the first step in deployment?
A. Register the model with Unity Catalog
B. Set up the serving infrastructure
C. Create a retrieval index
D. Write endpoint documentation

When building a vector search index, what is a key consideration?
A. Ensuring all data is normalized to the same format
B. Minimizing the size of the index regardless of document size
C. Using static embeddings only
D. Avoiding semantic search approaches

What resource is most important for serving a Foundation Model API in production?
A. Large memory allocation
B. Access to low-latency disk storage
C. High bandwidth network connectivity
D. Additional CPUs for pre-processing tasks

How can a Generative AI Engineer optimize a RAG application’s feature serving?
A. Include redundant data sources for failover
B. Use inference caching for frequent queries
C. Avoid context-based retrieval steps
D. Serve all data in real time without caching

Section 5: Governance – 8%

Which technique can best mitigate risks from malicious user inputs in a generative AI application?
A. Avoid processing any user input
B. Implement masking techniques and robust input validation
C. Disable API access for external users
D. Increase logging for all user actions

A Generative AI application feeds off third-party datasets. What legal concern should the engineer address?
A. Ensuring all data is in English
B. Verifying data licensing and usage rights
C. Removing irrelevant data fields
D. Adding disclaimers to the application

Which action is an effective guardrail to prevent performance issues in an AI application?
A. Limit the number of users who can access the app
B. Use masking to reduce data processing load
C. Avoid training the model on complex datasets
D. Minimize the use of pre-trained models

What is the most effective way to mitigate problematic outputs from RAG applications?
A. Disable feedback mechanisms
B. Conduct manual data curation and review
C. Automate all data ingestion tasks
D. Avoid using embeddings in retrieval

Section 6: Evaluation and Monitoring – 12%

An engineer needs to monitor LLM cost efficiency for a RAG application. Which metric is most relevant?
A. Response diversity
B. Token usage per request
C. Retrieval accuracy
D. User satisfaction ratings

How should a Generative AI Engineer assess the performance of a deployed LLM?
A. Ignore inference logs and focus on user feedback
B. Use quantitative metrics such as BLEU and F1 scores
C. Focus only on cost-related metrics
D. Assess based on the LLM’s training perplexity

What is a key metric to monitor for a translation LLM deployment?
A. Latency of responses
B. Number of tokens generated per response
C. Accuracy of translations based on reference texts
D. Relevance of responses

How can inference logging improve a RAG application’s performance?
A. By eliminating the need for real-time monitoring
B. Providing insights into request patterns and errors
C. Reducing token count in generated responses
D. Increasing the application’s overall speed

A Generative AI Engineer is asked to monitor safety and fairness for an LLM’s deployment. What approach should they take?
A. Rely solely on automated tests
B. Use a mix of qualitative assessments and bias detection tools
C. Only evaluate the model’s training dataset
D. Ignore qualitative aspects and focus on performance metrics

What Databricks feature can assist in managing LLM costs for RAG applications?
A. Delta Sharing
B. MLflow cost optimization tools
C. Feature Store
D. Unity Catalog
